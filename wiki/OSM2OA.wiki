* Data synchronization from !OpenStreetMap to !OpenAddresses *

<wiki:toc max_depth="2" /> 

= Concept =

Address data are regularly transferred from OSM to OA.
OSM address are managed only in OSM. In that sense, they can't be modified in OA, but can only be viewed and used.

= Technical specification =

= Implementation =

== Language ==

Python scripts

== Environment ==

 * Dev environment: local computer
 * Test environment: geolin01.cti.ac.at 
 * Prod environment: c2cpc84.camptocamp.com

=== Workflow ===

==== Initial load ====

 1. On Test: delete osm data based on osmid
 1. On Test: global osm export
 1. On Test: creation of INSERT SQL Script
 1. On Test: start SQL Script
 1. On Test: user validation
 1. On Prod: import SQL script
 1. On Prod: delete osm data based on osmid
 1. On Prod: start SQL Script

Q: What do you mean by "import SQL Script" ? 
Simply transfer the sql file (scp) from one server to the other

==== Incremental load ====

 1. On Test: weekly cron:
  1. On Test: Export differential OSM file based on last changeset
  1. On Test: Creation of INSERT - UPDATE - DELETE SQL Script
  1. On Test: Start SQL Script
 1. On Test: user validation
 1. On Prod: import SQL script
 1. On Prod: start SQL script

Q: Do we really need this differential load? As we don't manage any of the OSM points, we can do an initial load every week. It's easier to program and I'm not sure we can get the right information we need from the OSM changesets ..
A: my concern is related to the downtime (since we have to delete and import). using SQL script is probably not the fastest import process. If we want to follow this path, I would use a temp table and then make a "insert into" SQL command. But, based on my experience with bulk import, this can take several minutes for millions of records. Another argument is that we have an archiving system. If we regularly delete and insert, then the archive tables will be huge and probably unmanageable.